{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql import SparkSession\n",
				"spark =  SparkSession.builder.getOrCreate()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"usersDf = spark.read.csv('s3://mui-input/songs/', header=True, inferSchema = True)\n",
				"songsDf = spark.read.csv('s3://mui-input/songs/', header=True, inferSchema = True)\n",
				"streamsDf = spark.read.csv('s3://mui-input/streams/', header=True, inferSchema = True)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, to_date\n",
				"from pyspark.sql import functions as F, Window\n",
				"\n",
				"\n",
				"def transform_data(spark, usersDf, songsDf, streamsDf):\n",
				"    \"\"\"drop/fill nulls, typecasting, remove duplicates\"\"\"\n",
				"    \n",
				"    #Convert listen_time to date.\n",
				"    streamsDf = streamsDf.withColumn(\"report_date\", to_date(streamsDf.listen_time))\n",
				"\n",
				"    \n",
				"    #filter invalid keys\n",
				"    streamsDf = streamsDf.dropna(subset=['user_id', 'track_id', 'listen_time'])\n",
				"    \n",
				"    #type casting of duration to long\n",
				"    songsDf = songsDf.withColumn(\"duration_ms\", col(\"duration_ms\").cast(\"long\"))\n",
				"    \n",
				"    return usersDf, songsDf, streamsDf\n",
				"        \n",
				"usersDf, songsDf, streamsDf = transform_data(spark, usersDf, songsDf, streamsDf)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"def load_data(spark, usersDf, songsDf, streamsDf):\n",
				"    db_name = \"music_insights\"\n",
				"    s3_output_path = \"s3://buckdemo2222/output/\"\n",
				"    \n",
				"     #Creating database if it doesnâ€™t exist\n",
				"    spark.sql(f\"CREATE DATABASE IF NOT EXISTS {db_name} LOCATION '{s3_output_path}';\")\n",
				"    \n",
				"    #Save dataframe as glue table\n",
				"    def save_as_table(df, table_name):\n",
				"        table_path = f\"{s3_output_path}{table_name}/\"\n",
				"        full_name = f\"{db_name}.{table_name}\"\n",
				"\n",
				"        print(f\"Writing table: {full_name}, {table_path}\")\n",
				"        df.write \\\n",
				"            .format(\"parquet\") \\\n",
				"            .mode(\"overwrite\") \\\n",
				"            .option(\"path\", table_path) \\\n",
				"            .saveAsTable(full_name)\n",
				"        print(f\"Created table: {full_name}\")\n",
				"    \n",
				"    save_as_table(songsDf, \"songs\")\n",
				"    save_as_table(usersDf, \"users\")\n",
				"    save_as_table(streamsDf, \"streams\")\n",
				"    \n",
				"    print(\"\\nRaw data successfully written to S3 and registered in Glue Catalog.\")\n",
				"    print(f\"Verify with: spark.sql('SHOW TABLES IN {db_name}').show()\")\n",
				"\n",
				"\n",
				"load_data(spark, usersDf, songsDf, streamsDf)\n"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Glue PySpark",
			"language": "python",
			"name": "glue_pyspark"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "Python_Glue_Session",
			"pygments_lexer": "python3"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}
